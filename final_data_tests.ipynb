{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training variables(at the top for quick access).\n",
    "NUM_TRIALS = 3\n",
    "FOLDS = 5\n",
    "DATA_SIZE = 500 #5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Helpers\n",
    "class Set:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "# splits targets from data, then splits training from testing data\n",
    "def get_training_test_sets(data, training_size=1000, pred_col='y'):\n",
    "    data_shuffled = data.sample(frac=1).reset_index(drop=True)\n",
    "    data_shuffled_y = pd.DataFrame(data_shuffled[pred_col])\n",
    "    data_shuffled_X = data_shuffled.drop(pred_col, 1)\n",
    "    tr_X = data_shuffled_X.iloc[:training_size, :].to_numpy()\n",
    "    tr_y = data_shuffled_y.iloc[:training_size, :].values.ravel()\n",
    "    tst_X = data_shuffled_X.iloc[training_size:, :].to_numpy()\n",
    "    tst_y = data_shuffled_y.iloc[training_size:, :].values.ravel()\n",
    "\n",
    "    training = Set(tr_X, tr_y)\n",
    "    testing = Set(tst_X, tst_y)\n",
    "    \n",
    "    return training, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(raw_data,\n",
    "               column_names=None,\n",
    "               binary_cols=None,\n",
    "               one_hot_cols=None,\n",
    "               continuous_cols=None,\n",
    "              ):\n",
    "    \n",
    "    final_data = raw_data\n",
    "    \n",
    "    if column_names is not None:\n",
    "        final_data.columns = column_names\n",
    "        \n",
    "        if binary_cols is not None:\n",
    "            for col in binary_cols:\n",
    "                match = final_data[col].unique()[0]\n",
    "                final_data[col] = (final_data[col] != match).astype(int)\n",
    "                \n",
    "        if one_hot_cols is not None:\n",
    "            final_data = pd.get_dummies(final_data, columns=one_hot_cols)\n",
    "            \n",
    "        if final_data.isna().values.any():\n",
    "            print('Warning!: missing data')\n",
    "            \n",
    "        if continuous_cols is not None:\n",
    "            col_names = final_data.columns\n",
    "            mask = np.isin(col_names, continuous_cols, invert=True)\n",
    "            not_continuous = col_names[mask]\n",
    "            \n",
    "            reordered_cols = np.concatenate((continuous_cols, not_continuous))\n",
    "            final_data = final_data[reordered_cols]\n",
    "            \n",
    "            # Normalize\n",
    "            ct = ColumnTransformer([\n",
    "                ('continuous', StandardScaler(), continuous_cols)\n",
    "                \n",
    "            ], remainder='passthrough')\n",
    "            \n",
    "            scaled = ct.fit_transform(final_data)\n",
    "            final_data = pd.DataFrame(scaled, columns=reordered_cols)\n",
    "            \n",
    "    else:\n",
    "        print('No columns names, returning raw data.')\n",
    "        \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set\n",
    "adults_raw = pd.read_csv('data/adults/adult.data', header=None)\n",
    "\n",
    "adult_process_params = {\n",
    "    'column_names': ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'y'],\n",
    "    'binary_cols': ['sex', 'y'],\n",
    "    'one_hot_cols': ['workclass', 'education', 'marital_status', 'occupation','relationship', 'race', 'native_country'],\n",
    "    'continuous_cols': ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week'],\n",
    "}\n",
    "\n",
    "adults = clean_data(adults_raw, **adult_process_params)\n",
    "# adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0...\n",
      ">acc=0.810, est=0.835, cfg={'C': 10, 'gamma': 0.01}\n",
      ">acc=0.820, est=0.853, cfg={'C': 1000, 'gamma': 0.001}\n",
      ">acc=0.860, est=0.845, cfg={'C': 100, 'gamma': 0.001}\n",
      ">acc=0.790, est=0.843, cfg={'C': 10, 'gamma': 0.01}\n",
      ">acc=0.850, est=0.840, cfg={'C': 10, 'gamma': 0.01}\n",
      "Accuracy: 0.826 (0.026)\n",
      "0.86\n",
      "Training Master: {'C': 100, 'gamma': 0.001}\n",
      "Check Acc on Entire set\n",
      "Final Acc = 0.838 \n",
      "\n",
      "Trial 1...\n",
      ">acc=0.800, est=0.840, cfg={'C': 10, 'gamma': 0.01}\n",
      ">acc=0.830, est=0.807, cfg={'C': 10, 'gamma': 0.01}\n",
      ">acc=0.870, est=0.828, cfg={'C': 10, 'gamma': 0.01}\n",
      ">acc=0.770, est=0.840, cfg={'C': 10, 'gamma': 0.01}\n",
      ">acc=0.870, est=0.828, cfg={'C': 10, 'gamma': 0.01}\n",
      "Accuracy: 0.828 (0.039)\n",
      "0.87\n",
      "Training Master: {'C': 10, 'gamma': 0.01}\n",
      "Check Acc on Entire set\n",
      "Final Acc = 0.833 \n",
      "\n",
      "Trial 2...\n",
      ">acc=0.810, est=0.823, cfg={'C': 1000, 'gamma': 0.001}\n",
      ">acc=0.760, est=0.823, cfg={'C': 1000, 'gamma': 0.001}\n",
      ">acc=0.770, est=0.832, cfg={'C': 10, 'gamma': 0.01}\n",
      ">acc=0.800, est=0.802, cfg={'C': 100, 'gamma': 0.001}\n",
      ">acc=0.830, est=0.795, cfg={'C': 10, 'gamma': 0.01}\n",
      "Accuracy: 0.794 (0.026)\n",
      "0.83\n",
      "Training Master: {'C': 10, 'gamma': 0.01}\n",
      "Check Acc on Entire set\n",
      "Final Acc = 0.835 \n",
      "\n",
      "CPU times: user 3.71 s, sys: 263 ms, total: 3.97 s\n",
      "Wall time: 8.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "p_grid = {'C': [1,10,100,1000], 'gamma': [0.001,0.01,0.1,1.0]}\n",
    "\n",
    "for i in range(NUM_TRIALS):\n",
    "    \n",
    "    training_set, testing_set = get_training_test_sets(adults, DATA_SIZE, pred_col='y')\n",
    "    \n",
    "    print('Trial {}...'.format(i))\n",
    "    trial_results = []\n",
    "    outer_cv = KFold(n_splits=FOLDS, shuffle=True, random_state=i)\n",
    "    best_p = []\n",
    "    best_score = []\n",
    "    \n",
    "    for tr_i, tst_i in outer_cv.split(training_set.X):\n",
    "        X_train, X_test = training_set.X[tr_i, :], training_set.X[tst_i, :]\n",
    "        y_train, y_test = training_set.y[tr_i], training_set.y[tst_i]\n",
    "\n",
    "        inner_cv = KFold(n_splits=FOLDS, shuffle=True, random_state=i)\n",
    "    \n",
    "        svm = SVC(kernel='rbf')\n",
    "\n",
    "        search = GridSearchCV(\n",
    "            estimator=svm,\n",
    "            param_grid=p_grid,\n",
    "            cv=inner_cv,\n",
    "            verbose=0,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            refit=True\n",
    "        )\n",
    "        \n",
    "        result = search.fit(X_train, y_train)\n",
    "        \n",
    "        model = result.best_estimator_\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        best_p.append(result.best_params_)\n",
    "        best_score.append(acc)\n",
    "        trial_results.append(acc)\n",
    "        \n",
    "        print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "        \n",
    "\n",
    "    print('Accuracy: %.3f (%.3f)' % (np.mean(trial_results), np.std(trial_results)))\n",
    "    \n",
    "    run = best_score.index(max(best_score))\n",
    "    best_best_p = best_p[run]\n",
    "    \n",
    "    oo_svm = SVC()\n",
    "    print('Training Master: %s' % best_best_p)\n",
    "    oo_svm.set_params(**best_best_p)\n",
    "    oo_svm.fit(training_set.X,training_set.y)\n",
    "    \n",
    "    print('Check Acc on Entire set')\n",
    "    y_pred = oo_svm.predict(testing_set.X)\n",
    "    acc = accuracy_score(testing_set.y, y_pred)\n",
    "    print('Final Acc = %.3f \\n' % acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
