{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training variables(at the top for quick access).\n",
    "NUM_TRIALS = 3\n",
    "FOLDS = 5\n",
    "DATA_SIZE = 500 #5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Helpers\n",
    "class Set:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "# splits targets from data, then splits training from testing data\n",
    "def get_training_test_sets(data, training_size=1000, pred_col='y'):\n",
    "    data_shuffled = data.sample(frac=1).reset_index(drop=True)\n",
    "    data_shuffled_y = pd.DataFrame(data_shuffled[pred_col])\n",
    "    data_shuffled_X = data_shuffled.drop(pred_col, 1)\n",
    "    tr_X = data_shuffled_X.iloc[:training_size, :].to_numpy()\n",
    "    tr_y = data_shuffled_y.iloc[:training_size, :].values.ravel()\n",
    "    tst_X = data_shuffled_X.iloc[training_size:, :].to_numpy()\n",
    "    tst_y = data_shuffled_y.iloc[training_size:, :].values.ravel()\n",
    "\n",
    "    training = Set(tr_X, tr_y)\n",
    "    testing = Set(tst_X, tst_y)\n",
    "    \n",
    "    return training, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(raw_data,\n",
    "               column_names=None,\n",
    "               binary_cols=None,\n",
    "               one_hot_cols=None,\n",
    "               continuous_cols=None,\n",
    "              ):\n",
    "    \n",
    "    final_data = raw_data\n",
    "    \n",
    "    if column_names is not None:\n",
    "        final_data.columns = column_names\n",
    "        \n",
    "        if binary_cols is not None:\n",
    "            for col in binary_cols:\n",
    "                if type(col) is tuple:\n",
    "                    match = col[1]\n",
    "                    ind = col[0]\n",
    "                else:\n",
    "                    match = final_data[col].unique()[0]\n",
    "                    ind = col\n",
    "                final_data[ind] = (final_data[ind] != match).astype(int)\n",
    "                \n",
    "        if one_hot_cols is not None:\n",
    "            final_data = pd.get_dummies(final_data, columns=one_hot_cols)\n",
    "            \n",
    "        if final_data.isna().values.any():\n",
    "            print('Warning!: missing data')\n",
    "            \n",
    "        if continuous_cols is not None:\n",
    "            col_names = final_data.columns\n",
    "            mask = np.isin(col_names, continuous_cols, invert=True)\n",
    "            not_continuous = col_names[mask]\n",
    "            \n",
    "            reordered_cols = np.concatenate((continuous_cols, not_continuous))\n",
    "            final_data = final_data[reordered_cols]\n",
    "            \n",
    "            # Normalize\n",
    "            ct = ColumnTransformer([\n",
    "                ('continuous', StandardScaler(), continuous_cols)\n",
    "                \n",
    "            ], remainder='passthrough')\n",
    "            \n",
    "            scaled = ct.fit_transform(final_data)\n",
    "            final_data = pd.DataFrame(scaled, columns=reordered_cols)\n",
    "            \n",
    "    else:\n",
    "        print('No columns names, returning raw data.')\n",
    "        \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set\n",
    "adults_raw = pd.read_csv('data/adults/adult.data', header=None)\n",
    "\n",
    "eye_arff = arff.loadarff('data/eeg_eye/EEG_Eye_State.arff')\n",
    "eyes_raw = pd.DataFrame(eye_arff[0])\n",
    "\n",
    "covertype_raw = pd.read_csv('data/covertype/covtype.data', header=None)\n",
    "\n",
    "\n",
    "\n",
    "adult_process_params = {\n",
    "    'column_names': ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'y'],\n",
    "    'binary_cols': ['sex', 'y'],\n",
    "    'one_hot_cols': ['workclass', 'education', 'marital_status', 'occupation','relationship', 'race', 'native_country'],\n",
    "    'continuous_cols': ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week'],\n",
    "}\n",
    "\n",
    "eyes_process_params = {\n",
    "    'column_names': ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4', 'y'],\n",
    "    'binary_cols': ['y'],\n",
    "    'continuous_cols': ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']\n",
    "}\n",
    "\n",
    "# [('y', 2)], # lodgepole pine\n",
    "covtyp_process_params = {\n",
    "    'column_names': ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area_0', 'Wilderness_Area_1', 'Wilderness_Area_2', 'Wilderness_Area_3', 'Soil_Type0', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'y'],\n",
    "    'binary_cols': [('y', 2)],\n",
    "    'continuous_cols': ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points'],\n",
    "}\n",
    "# Cover Type column names can be rebuilt with the code below if need be.\n",
    "# cov_cols = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']\n",
    "# Wilderness_Area = ['Wilderness_Area_{}'.format(i) for i in range(4)]\n",
    "# Soil_Type = ['Soil_Type{}'.format(i) for i in range(40)]\n",
    "# cov_cols = np.concatenate((cov_cols, Wilderness_Area, Soil_Type, ['y']))\n",
    "# covertype_raw.columns = cov_cols\n",
    "\n",
    "adults = clean_data(adults_raw, **adult_process_params)\n",
    "eyes = clean_data(eyes_raw, **eyes_process_params)\n",
    "pines = clean_data(covertype_raw, **covtyp_process_params)\n",
    "# print(adults.head())\n",
    "# print(eyes.head())\n",
    "# print(pines.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0...\n",
      ">acc=0.880, est=0.865, cfg={'C': 10, 'gamma': 0.01}\n",
      ">acc=0.850, est=0.843, cfg={'C': 100, 'gamma': 0.001}\n",
      ">acc=0.840, est=0.855, cfg={'C': 1, 'gamma': 0.1}\n",
      ">acc=0.880, est=0.848, cfg={'C': 1, 'gamma': 0.1}\n",
      ">acc=0.880, est=0.867, cfg={'C': 1, 'gamma': 0.1}\n",
      "Accuracy: 0.866 (0.017)\n",
      "Training Master: {'C': 10, 'gamma': 0.01}\n",
      "Check Acc on Entire set\n",
      "Final Acc = 0.840 \n",
      "\n",
      "Trial 1...\n",
      ">acc=0.790, est=0.840, cfg={'C': 1, 'gamma': 0.1}\n",
      ">acc=0.830, est=0.823, cfg={'C': 10, 'gamma': 0.01}\n",
      ">acc=0.820, est=0.835, cfg={'C': 10, 'gamma': 0.01}\n",
      ">acc=0.820, est=0.828, cfg={'C': 1, 'gamma': 0.1}\n",
      ">acc=0.840, est=0.835, cfg={'C': 10, 'gamma': 0.01}\n",
      "Accuracy: 0.820 (0.017)\n",
      "Training Master: {'C': 10, 'gamma': 0.01}\n",
      "Check Acc on Entire set\n",
      "Final Acc = 0.838 \n",
      "\n",
      "Trial 2...\n",
      ">acc=0.850, est=0.838, cfg={'C': 1, 'gamma': 0.1}\n",
      ">acc=0.840, est=0.823, cfg={'C': 100, 'gamma': 0.1}\n",
      ">acc=0.760, est=0.853, cfg={'C': 1000, 'gamma': 0.001}\n",
      ">acc=0.800, est=0.840, cfg={'C': 1, 'gamma': 0.1}\n",
      ">acc=0.850, est=0.840, cfg={'C': 100, 'gamma': 0.001}\n",
      "Accuracy: 0.820 (0.035)\n",
      "Training Master: {'C': 1, 'gamma': 0.1}\n",
      "Check Acc on Entire set\n",
      "Final Acc = 0.834 \n",
      "\n",
      "CPU times: user 3.9 s, sys: 273 ms, total: 4.17 s\n",
      "Wall time: 8.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "p_grid = {'C': [1,10,100,1000], 'gamma': [0.001,0.01,0.1,1.0]}\n",
    "\n",
    "for i in range(NUM_TRIALS):\n",
    "    \n",
    "    training_set, testing_set = get_training_test_sets(adults, DATA_SIZE, pred_col='y')\n",
    "    \n",
    "    print('Trial {}...'.format(i))\n",
    "    trial_results = []\n",
    "    outer_cv = KFold(n_splits=FOLDS, shuffle=True, random_state=i)\n",
    "    best_p = []\n",
    "    best_score = []\n",
    "    \n",
    "    for tr_i, tst_i in outer_cv.split(training_set.X):\n",
    "        X_train, X_test = training_set.X[tr_i, :], training_set.X[tst_i, :]\n",
    "        y_train, y_test = training_set.y[tr_i], training_set.y[tst_i]\n",
    "\n",
    "        inner_cv = KFold(n_splits=FOLDS, shuffle=True, random_state=i)\n",
    "    \n",
    "        svm = SVC(kernel='rbf')\n",
    "\n",
    "        search = GridSearchCV(\n",
    "            estimator=svm,\n",
    "            param_grid=p_grid,\n",
    "            cv=inner_cv,\n",
    "            verbose=0,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            refit=True\n",
    "        )\n",
    "        \n",
    "        result = search.fit(X_train, y_train)\n",
    "        \n",
    "        model = result.best_estimator_\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        best_p.append(result.best_params_)\n",
    "        best_score.append(acc)\n",
    "        trial_results.append(acc)\n",
    "        \n",
    "        print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "        \n",
    "\n",
    "    print('Accuracy: %.3f (%.3f)' % (np.mean(trial_results), np.std(trial_results)))\n",
    "    \n",
    "    run = best_score.index(max(best_score))\n",
    "    best_best_p = best_p[run]\n",
    "    \n",
    "    oo_svm = SVC()\n",
    "    print('Training Master: %s' % best_best_p)\n",
    "    oo_svm.set_params(**best_best_p)\n",
    "    oo_svm.fit(training_set.X,training_set.y)\n",
    "    \n",
    "    print('Check Acc on Entire set')\n",
    "    y_pred = oo_svm.predict(testing_set.X)\n",
    "    acc = accuracy_score(testing_set.y, y_pred)\n",
    "    print('Final Acc = %.3f \\n' % acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
